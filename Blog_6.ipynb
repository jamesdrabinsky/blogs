{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog post I will explain how to scrape twitter data using Twython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import Twython  \n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input your security information that you get from the twitter API.\n",
    "- Create your query.  Here, I am querying all tweets with the hashtag #FantasticBeasts, of the 'recent' type, in English, a count of 100 tweets and the full text of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pass security information to variables\n",
    "consumer_key = \"XVFBqWVkhDlRBFz2f7CbvIiXI\"\n",
    "consumer_secret = \"S4BO3WQpFHRX3q0vOTGZvre3TIPyxtt6w3WTPAexqNtii5fsIw\"\n",
    "access_key = \"1034835017371770880-b4eFRilbAVFpPwA5tTXRp2JBhr6rWK\"\n",
    "access_secret = \"VWAg8gzTHPXJxfY9GwGkcI2iuplAtw5NxhhnQPcbNwKRr\"\n",
    "\n",
    "# Instantiate an object\n",
    "new_tweets = Twython(consumer_key, consumer_secret)\n",
    "\n",
    "# Create our query\n",
    "query = {'q': '#FantasticBeasts',  \n",
    "        'result_type': 'recent',\n",
    "        'lang': 'en',\n",
    "        'count': 100,\n",
    "        'tweet_mode':'extended'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This code allows you to scrape multiple pages (100 tweets per page).\n",
    "- Thids will return the username, date and text of the tweet.  \n",
    "- When querying for the full text of the tweet, there is difference in how call retweeted tweets and non-retweeted tweets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_ = {'user': [], 'date': [], 'text': []}  \n",
    "npages = 10\n",
    "for i in range(npages):\n",
    "    # Search tweets\n",
    "    print('Processing {0} out {1} pages'.format(i,npages))\n",
    "    results = new_tweets.search(**query)\n",
    "    \n",
    "    \n",
    "    for status in results['statuses']:  \n",
    "        dict_['user'].append(status['user']['screen_name'])\n",
    "        dict_['date'].append(status['created_at'])\n",
    "        if status.get('retweeted_status'):\n",
    "            dict_['text'].append(status['retweeted_status']['full_text'])\n",
    "        else:\n",
    "            dict_['text'].append(status['full_text'])\n",
    "            \n",
    "    query['max_id'] = results['statuses'][-1]['id_str']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
